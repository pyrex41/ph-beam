# Project 1 - MVP Notes
#gauntlet #figma-clone
* starting with PRD generation
  * Claude Sonnet-4.5, grok 4 <—> crossfeed output to get “best of the best”
    * Pursueing multiple possible archetectures
      * Simple: Firebase + Svelte + Bun / Elysia
        * Using task-master to generate tasks
        * Lots of issue getting environment and websockets
          * non-standard stack, didn’t feed in the docs well
      * Performant: Phoenix liveview w/ redis, pixijs
        * 
      * Fun/divergent/performant: Common Lisp + vanlla js, pixiJS
        * https://claude.ai/share/55112f99-d66c-4c48-8371-e8462576928e
        * Utilizing task-master
    * tm workflow (i use grok-code-fast-1 for task parsing — very fast, so far good enough)
      * Generate PRD in claude web (some input from Grok).
      * tm parse-prd -n 10
      * tm analyze complexity
      * review tassks, complexity report
      * edit as needed (via prompts in claudetm  code if complex)
      * generate mermaid files in claude web
      * have claude code review / edit mermaid files for compliance to prd and tasks
      * tm expand —all
      * have claude code update its .md files with all the added context / files
      * git commit
    * Begin working: “please begin working on the task master tasks. work in parallel where possible using subagents and/or task executor. Invoke multiple agents / tasks in a single task invocation”
      * still have a hard time getting in parallel
      * T5CLw_Byum_hSnPMwONJXw3kHkDb2VsXXf-GU-GENg_89sHR9Mx2H9qNRvQsGJU5.  
  * I figured the common list one would be the least functional but the most interesting. So I worked on that in parallel with the JavaScript spelt front end and I just let AI run in the background on the Phoenix one which I thought might be a great architecture but would be the most difficult and problematic. Weirdly, whatever prompts I gave the Phoenix one and the tasks I created in Taskmaster it just kept running. It ran through all the tasks, got it all done and came up with something that almost completely functioned. I just had to make some changes to get the canvas functionality to work but even those changes worked really quickly and it was the first one I got done. And then the common list one came next and I've had the most issues with the JavaScript one. I'll be at probably because I'm using bun instead of node and independency help but with good templating ahead of time and like a rock solid template to start with probably would have been the quickest but still.
  - [ ] 
  * So, as I was working on this, I decided to do three different versions at once. It, I picked one that I thought would be fairly quick and easy. It was going to be Svelte because I just don't love React. And I like Bunn and Elyse because it's more performant. So I thought that that would be easy enough because I've done stuff with that in the past with AI. So I went down that route and then I also created PRDs for two different stacks. One that was kind of off the wall with a common lisp back end and then another which if I was going to do in production I felt like would be the best route but I thought it would take the most time. But I went ahead and did a PRD since it's not that hard to do three at once of the same thing. And that one was using Phoenix and Elixir for the back end. For all three I picked Pixi.js for the front end because of its higher performance than some of the other JavaScript frameworks I looked at. And then I started working all those in separate cloud codes, in separate tabs. For whatever reason, so after I did that I would create task manager tasks for each one and analyze the PRD, break it out, evaluate the tasks. I spent the least amount of time looking at the Elixir one because I thought when my attention got shorter I figured that's the one that's least likely to get done. Once the tasks look good I just let it go and for whatever reason usually Cloud Code will do a task and then come back and ask what I want to do next and it just kept going. It worked through all the tasks that I had and ended up with something that was very, very good. I had to go back and make some, you know, the canvas wasn't working. We had to make a few adjustments there to get the canvas working but once I hooked things up it just worked. I had tons of issues with the Bun, Elixir one because it kept trying to run things in the node and I don't think I started off getting my, getting my rules and stuff set up in place to really communicate that, what stack that I wanted so it kept trying to replace it with the stack and we didn't get the web socket's working. Before I even got that one finished the common list one actually was working pretty well. It's a little bit buggerier on some issues but mostly like really fast drag and drop and that kind of stuff. I like that one because the deployment's pretty easy. You can get it down to a binary so deployment is really simple with that one. I used Auth0 for the Elixir one, for Auth and was going to use that for the Bun one. Eventually I was going to do that for common list but I never got there. It's just simple password, email, Auth, integrated, straight in the common list back in. I've got a PRD feature in place to add something there but I set that one aside because I'm going to move forward with the Elixir one because it just, it performed the best, it looked the nicest and I think it's the most, the strongest platform here to move forward so that's the one I'm going to go with.
* I mostly use cloud code. I use cursor some. I find cursor still the easiest way to go actually look at the files. That's when there's specific things to look at and then I just use the cursor window to do some edits there. Sometimes it's just easier. But generally use cloud code in Taskmaster for managing tasks. I also use grokfast, a code 1 model, which for that instead of using cursor, which I totally could have, but I use open code. I have my open code setup so it only uses the grok model. So when I want to use grok, I go use that. And I was surprised. It's harder to direct when it tells not to code. It ignores me and just goes in codes. But it was able to handle some... It also is terrible at generating documents. When I say generate a markdown, it'll generate what should be in the markdown and has trouble creating markdown like stupid stuff. But it was really good at doing some things that I thought were going to be kind of bigger problems. I tended to create a separate work tree when I would do that because I was kind of worried it wasn't going to work. But it was so fast and I would have cloud code check it and I'd look at the output in the diff and it looked great. So I was surprised I had pretty good results. And it's so fast that I would love to figure out a way to integrate it as a tool in cloud that I can specifically tell it to go prompt the grok model to go do some things and kind of integrate it maybe. I want to keep hand holding it because there's times it just doesn't know what to do or things like that. I wish it had better tooling around it because maybe I should try using it in the cursor but for whatever reason I've gravitated towards the CLI tools more.
* I didn't end up using memory bank in part because I was using cloud code in Taskmaster instead. But I did find that I spent based on the class with Ash, I spent more time than I have in the past really double checking the tasks and the sub tasks and the way that they get expanded by Taskmaster and making sure that looked right. Unfortunately, I can't remember how much time I spent on the Elixir one, the one that really worked well. I think I spent less time on that. I think the PRD just ended up being really good. I also think this is something that I've toyed with while I've used Elm on the front end sometimes because I like that it has to compile and the strong type system really enforces you to catch a lot of errors before it can even run. And I've had pretty good results on front end using that with AI because I can create a rule and cursor or put it in the cloud code MD file that it needs to make sure that any file that it changes compiles correctly and that the whole project compiles or else it didn't do something right and it needs to go back and check that. And Elm has really nice debugger messages that are pretty solid guidance on where exactly the issues are. I really haven't done a lot with Elixir. I love the design philosophy, but I've really never done anything beyond toy tutorials. Man, I'm not really sure if it has that same kind of helpful output, but the functional nature of it and the fact that it has to compile I think may have ended up really helping Clawed see where it was stuck and keep going. This is by far the best result so that I've had for something like that. I think putting some extra time in on the planning and having a really full featured product requirements document. I thought that I did that in the past, but I think that based on our discussion with Ash I put more detail into that and more time in making sure it was correct and that went a long, long ways in getting this right.
